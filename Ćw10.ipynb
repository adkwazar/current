{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Generowanie nowego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('cytaty.txt','r')  #otwiram plik z cytatami\n",
    "cytaty = f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best and most beautiful things in the world cannot be seen or even touched - they must be felt with the heart.',\n",
       " 'The best preparation for tomorrow is doing your best today.',\n",
       " 'Put your heart, mind, and soul into even your smallest acts. This is the secret of success.',\n",
       " \"I can't change the direction of the wind, but I can adjust my sails to always reach my destination.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cytaty[:4] #pierwsze cztery cytaty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cytaty) #ile wszysktich cytatow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a small seed a mighty trunk may grow.\n"
     ]
    }
   ],
   "source": [
    "cytat9 = cytaty[9] #wybieram przykladowy cytat\n",
    "print(cytat9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cytat9) #ile ma znakow?                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(cytat9)) + [\"<BOS>\", \"<EOS>\"] #tworze liste znakow ktore wystepują w wybranym cytacie, dodaje dwa nowe BOS = początek sekwencji, EOS = koniec sekwencji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'F', 'y', 'o', '.', 'u', 'w', 't', 'k', ' ', 'e', 'r', 'l', 'i', 'g', 's', 'm', 'a', 'h', 'n', '<BOS>', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) #ile jest znakow unikalnych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) #zapisuje te informacje pod zmienną"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tworze dwa pomocnicze słowniki\n",
    "vocab1 = {s: i for i, s in enumerate(vocab)}\n",
    "vocab2 = {i: s for i, s in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d': 0, 'F': 1, 'y': 2, 'o': 3, '.': 4, 'u': 5, 'w': 6, 't': 7, 'k': 8, ' ': 9, 'e': 10, 'r': 11, 'l': 12, 'i': 13, 'g': 14, 's': 15, 'm': 16, 'a': 17, 'h': 18, 'n': 19, '<BOS>': 20, '<EOS>': 21}\n"
     ]
    }
   ],
   "source": [
    "print(vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'd', 1: 'F', 2: 'y', 3: 'o', 4: '.', 5: 'u', 6: 'w', 7: 't', 8: 'k', 9: ' ', 10: 'e', 11: 'r', 12: 'l', 13: 'i', 14: 'g', 15: 's', 16: 'm', 17: 'a', 18: 'h', 19: 'n', 20: '<BOS>', 21: '<EOS>'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uwaga: tak sie definiuje macierz jednostkową, my będziemy interpretowac wiersze jako reprezentacje one-hot vectors dla znakow\n",
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: \n",
    "\n",
    "class TextGenerator(nn.Module):\n",
    "    def __init__(self, v_size, hidden_size, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.ident = torch.eye(v_size) #macierz wektorow one-hot encoding dla wszytkich znakow\n",
    "        self.gru = nn.GRU(v_size, hidden_size, n_layers, batch_first=True) #uzyjemy sobie GRU\n",
    "        self.decoder = nn.Linear(hidden_size, v_size) #jako dekoder wezmiemy przeksztalcenie liniowe\n",
    "    \n",
    "    def forward(self, inp, hidden=None):\n",
    "        inp = self.ident[inp]                  #one-hot vector dla kolejnego znaku\n",
    "        output, hidden = self.gru(inp, hidden) #zastosowanie GRU\n",
    "        output = self.decoder(output)          #rozklad kolejnych znakow\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerator(vocab_size, 16) #buduje model, z wymiarem dla stanu ukrytego = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #funkcja kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20]])\n"
     ]
    }
   ],
   "source": [
    "bos = torch.Tensor([vocab1[\"<BOS>\"]]).long().unsqueeze(0) #zaczynamy od BOS - patrzymy jaki ma indeks\n",
    "print(bos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0623, -0.2222, -0.0150,  0.1365,  0.0983,  0.1993,  0.1391,\n",
      "          -0.1728, -0.0231, -0.2330, -0.2657,  0.1632, -0.0490, -0.2230,\n",
      "           0.1564,  0.1299,  0.1966, -0.0765,  0.2454, -0.0259, -0.1660,\n",
      "          -0.0031]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output, hidden = model(bos, hidden=None)\n",
    "print(output) #rozklad po pierwszym tokenie - tensor 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0623, -0.2222, -0.0150,  0.1365,  0.0983,  0.1993,  0.1391, -0.1728,\n",
      "         -0.0231, -0.2330, -0.2657,  0.1632, -0.0490, -0.2230,  0.1564,  0.1299,\n",
      "          0.1966, -0.0765,  0.2454, -0.0259, -0.1660, -0.0031]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output.reshape(-1, vocab_size)) #tensor 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([vocab1[cytat9[0]]]).long().unsqueeze(0) #pierwszy znak z cytatu \n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3223, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(criterion(output.reshape(-1, vocab_size), target.reshape(-1))) #wartosc funkcji kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie1: Wyjaśnij skąd wzięła się wartość funkcji kosztu (wyznacz ją poprzez bezpośrednie obliczenia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0276, -0.2690,  0.0260,  0.1704,  0.1412,  0.2731,  0.1469,\n",
      "          -0.2622, -0.0477, -0.1721, -0.2899,  0.1170,  0.0115, -0.2258,\n",
      "           0.1195,  0.1773,  0.2310, -0.0768,  0.2129, -0.0802, -0.1289,\n",
      "           0.0324]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output, hidden = model(target, hidden) #uzyj hidden do wygenerowania nowego output i hidden\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9920, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([vocab1[cytat9[1]]]).long().unsqueeze(0) #drugi znak w cytacie\n",
    "print(criterion(output.reshape(-1, vocab_size), target.reshape(-1)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(3.0214, grad_fn=<NllLossBackward0>)\n",
      "3 tensor(2.9355, grad_fn=<NllLossBackward0>)\n",
      "4 tensor(3.4547, grad_fn=<NllLossBackward0>)\n",
      "5 tensor(3.2883, grad_fn=<NllLossBackward0>)\n",
      "6 tensor(3.2219, grad_fn=<NllLossBackward0>)\n",
      "7 tensor(2.8485, grad_fn=<NllLossBackward0>)\n",
      "8 tensor(2.9043, grad_fn=<NllLossBackward0>)\n",
      "9 tensor(3.1984, grad_fn=<NllLossBackward0>)\n",
      "10 tensor(3.0012, grad_fn=<NllLossBackward0>)\n",
      "11 tensor(3.0398, grad_fn=<NllLossBackward0>)\n",
      "12 tensor(3.4019, grad_fn=<NllLossBackward0>)\n",
      "13 tensor(2.8991, grad_fn=<NllLossBackward0>)\n",
      "14 tensor(3.3230, grad_fn=<NllLossBackward0>)\n",
      "15 tensor(3.3401, grad_fn=<NllLossBackward0>)\n",
      "16 tensor(3.1339, grad_fn=<NllLossBackward0>)\n",
      "17 tensor(3.4604, grad_fn=<NllLossBackward0>)\n",
      "18 tensor(3.2840, grad_fn=<NllLossBackward0>)\n",
      "19 tensor(3.2394, grad_fn=<NllLossBackward0>)\n",
      "20 tensor(2.8135, grad_fn=<NllLossBackward0>)\n",
      "21 tensor(3.4494, grad_fn=<NllLossBackward0>)\n",
      "22 tensor(2.9808, grad_fn=<NllLossBackward0>)\n",
      "23 tensor(2.7827, grad_fn=<NllLossBackward0>)\n",
      "24 tensor(3.3134, grad_fn=<NllLossBackward0>)\n",
      "25 tensor(3.1247, grad_fn=<NllLossBackward0>)\n",
      "26 tensor(3.3166, grad_fn=<NllLossBackward0>)\n",
      "27 tensor(3.3861, grad_fn=<NllLossBackward0>)\n",
      "28 tensor(2.9354, grad_fn=<NllLossBackward0>)\n",
      "29 tensor(2.8927, grad_fn=<NllLossBackward0>)\n",
      "30 tensor(3.2009, grad_fn=<NllLossBackward0>)\n",
      "31 tensor(3.0539, grad_fn=<NllLossBackward0>)\n",
      "32 tensor(3.4310, grad_fn=<NllLossBackward0>)\n",
      "33 tensor(2.8131, grad_fn=<NllLossBackward0>)\n",
      "34 tensor(3.2337, grad_fn=<NllLossBackward0>)\n",
      "35 tensor(3.1051, grad_fn=<NllLossBackward0>)\n",
      "36 tensor(3.2736, grad_fn=<NllLossBackward0>)\n",
      "37 tensor(3.1144, grad_fn=<NllLossBackward0>)\n",
      "38 tensor(2.9706, grad_fn=<NllLossBackward0>)\n",
      "39 tensor(2.9909, grad_fn=<NllLossBackward0>)\n",
      "40 tensor(2.9985, grad_fn=<NllLossBackward0>)\n",
      "41 tensor(3.1145, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#analogicznie dla pozotalych znakow\n",
    "for i in range(2, len(cytat9)):\n",
    "    output, hidden = model(target, hidden) #generuje hidden i output w oparciu o poprzedni znak i hidden\n",
    "    target = torch.Tensor([vocab1[cytat9[i]]]).long().unsqueeze(0) #jaki mial byc kolejny znak?\n",
    "    loss = criterion(output.reshape(-1, vocab_size),target.reshape(-1)) #na ile sie pokrywa przewidywany znak z tym co generuje model      \n",
    "    print(i, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0567, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#na koncu dla znaku konca sekwencji\n",
    "output, hidden = model(target, hidden)\n",
    "target = torch.Tensor([vocab1[\"<EOS>\"]]).long().unsqueeze(0)\n",
    "loss = criterion(output.reshape(-1, vocab_size),target.reshape(-1))             \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Krótsze rozwiązanie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BOS>', 'F', 'r', 'o', 'm', ' ', 'a', ' ', 's', 'm', 'a', 'l', 'l', ' ', 's', 'e', 'e', 'd', ' ', 'a', ' ', 'm', 'i', 'g', 'h', 't', 'y', ' ', 't', 'r', 'u', 'n', 'k', ' ', 'm', 'a', 'y', ' ', 'g', 'r', 'o', 'w', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "cytat_ch = [\"<BOS>\"] + list(cytat9) + [\"<EOS>\"]\n",
    "print(cytat_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 1, 11, 3, 16, 9, 17, 9, 15, 16, 17, 12, 12, 9, 15, 10, 10, 0, 9, 17, 9, 16, 13, 14, 18, 7, 2, 9, 7, 11, 5, 19, 8, 9, 16, 17, 2, 9, 14, 11, 3, 6, 4, 21]\n"
     ]
    }
   ],
   "source": [
    "cytat_indices = [vocab1[ch] for ch in cytat_ch] #indeksy\n",
    "print(cytat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20,  1, 11,  3, 16,  9, 17,  9, 15, 16, 17, 12, 12,  9, 15, 10, 10,  0,\n",
      "          9, 17,  9, 16, 13, 14, 18,  7,  2,  9,  7, 11,  5, 19,  8,  9, 16, 17,\n",
      "          2,  9, 14, 11,  3,  6,  4, 21]])\n"
     ]
    }
   ],
   "source": [
    "cytat_tensor = torch.Tensor(cytat_indices).long().unsqueeze(0) #przerabiamy na tensor\n",
    "print(cytat_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 44])\n"
     ]
    }
   ],
   "source": [
    "print(cytat_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20,  1, 11,  3, 16,  9, 17,  9, 15, 16, 17, 12, 12,  9, 15, 10, 10,  0,\n",
      "          9, 17,  9, 16, 13, 14, 18,  7,  2,  9,  7, 11,  5, 19,  8,  9, 16, 17,\n",
      "          2,  9, 14, 11,  3,  6,  4]])\n"
     ]
    }
   ],
   "source": [
    "print(cytat_tensor[:,:-1])  #bez EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 11,  3, 16,  9, 17,  9, 15, 16, 17, 12, 12,  9, 15, 10, 10,  0,  9,\n",
      "         17,  9, 16, 13, 14, 18,  7,  2,  9,  7, 11,  5, 19,  8,  9, 16, 17,  2,\n",
      "          9, 14, 11,  3,  6,  4, 21]])\n"
     ]
    }
   ],
   "source": [
    "print(cytat_tensor[:,1:])  #bez BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1317, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#mozna przejsc wszystkie znaki bez pętli for\n",
    "\n",
    "output, hidden = model(cytat_tensor[:,:-1])\n",
    "target = cytat_tensor[:,1:]                 \n",
    "loss = criterion(output.reshape(-1, vocab_size), target.reshape(-1))\n",
    "print(loss) #taka zbiorcza wartosc funkcji kosztu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 300] Loss value: 1.0709996223449707\n",
      "[Iter 600] Loss value: 0.15126468241214752\n",
      "[Iter 900] Loss value: 0.04709853604435921\n",
      "[Iter 1200] Loss value: 0.02358001098036766\n",
      "[Iter 1500] Loss value: 0.014323363080620766\n",
      "[Iter 1800] Loss value: 0.009610854089260101\n",
      "[Iter 2100] Loss value: 0.006851714104413986\n",
      "[Iter 2400] Loss value: 0.0050923689268529415\n",
      "[Iter 2700] Loss value: 0.0039008131716400385\n",
      "[Iter 3000] Loss value: 0.0030554949771612883\n"
     ]
    }
   ],
   "source": [
    "#Trening \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #optymalizator\n",
    "criterion = nn.CrossEntropyLoss()                          #funkcja kosztu\n",
    "for it in range(3000):\n",
    "    optimizer.zero_grad()\n",
    "    output, hidden = model(cytat_tensor[:,:-1])\n",
    "    loss = criterion(output.reshape(-1, vocab_size),target.reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (it+1) % 300 == 0:  #jak sobie radzi nasz model co 100 epoke?\n",
    "        print(f\"[Iter {it+1}] Loss value: {float(loss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Generowanie nowego tekstu na podstawie modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja do generowania nowej sekwencji\n",
    "#będziemy lekko modyfikowac prawdopodobienstwa wylosowania danego znaku poprzez czynnik temperaturowy, gdy T=1, to nie zmieniamy, gdy T<1 to zwiększamy prp wystapienia najbardziej prawdopodobnych znakow, gdy T>1 to zmniejszamy prp najbardziej prawdopodobnych znakow\n",
    "\n",
    "\n",
    "def sample_sequence(model, max_len=100, temperature=0.8):\n",
    "    generated_sequence = \"\" #tu będzie przechowywana wygenerowana sekwencja\n",
    "    inp = torch.Tensor([vocab1[\"<BOS>\"]]).long() #zaczynamy od BOS\n",
    "    hidden = None\n",
    "    for p in range(max_len):\n",
    "        output, hidden = model(inp.unsqueeze(0), hidden) #co nam przeiwduje model?\n",
    "        output_dist = output.data.view(-1).div(temperature).exp() #uwzględniamy czynnik temperaturowy\n",
    "        top_i = int(torch.multinomial(output_dist, 1)[0]) #indeks przewidywanego znaku\n",
    "        predicted_char = vocab2[top_i] #przewidywany znak\n",
    "        if predicted_char == \"<EOS>\": #jakim przewidywanym znakiem jest EOS to konczymy\n",
    "            break\n",
    "        generated_sequence += predicted_char #dodajemy kolejny znak\n",
    "        inp = torch.Tensor([top_i]).long() #zapisujemy indeks w postaci tensora\n",
    "    return generated_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a small seed a mighty trunk may grow.\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature=0.4)) #T=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a small seed a mighty trunk may grow.\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature=1.0)) #T=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a small seed a mighty ttunk may groy.\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature=1.5)) #T=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a small seed ay aytw.rFrlr<BOS>may g\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature=2.0)) #T=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wFeoo.sFiyk.mhtyoswnFFkmsrt iuumunk hlgiunk\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature=5.0))  #T=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Analiza wszytkich cytatów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "text_field = Field(sequential=True, tokenize=lambda x: x, include_lengths=True, batch_first=True, use_vocab=True, init_token=\"<BOS>\", eos_token=\"<EOS>\")    \n",
    "fields = [('text', text_field)]\n",
    "cytaty = TabularDataset(\"cytaty.txt\", \"csv\", fields) #laduje sobie dane jeszcze raz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cytaty) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.build_vocab(cytaty)\n",
    "\n",
    "vocab1 = text_field.vocab.stoi #nie musimy tego robic ręcznie\n",
    "vocab2 = text_field.vocab.itos #nie musimy tego robic ręcznie\n",
    "vocab_size = len(text_field.vocab.itos)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([41, 41, 41, 41, 40, 40, 40, 40, 40, 38, 38, 38, 38, 38, 37, 37])\n",
      "tensor([37, 37, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 35, 35, 35, 35])\n",
      "tensor([86, 85, 84, 84, 83, 83, 83, 83, 82, 82, 82, 82, 81, 81, 81, 80])\n",
      "tensor([35, 34, 34, 34, 33, 33, 33, 33, 32, 32, 31, 31, 30, 30, 30, 30])\n",
      "tensor([63, 63, 63, 62, 62, 61, 61, 61, 61, 60, 60, 60, 60, 59, 59, 59])\n",
      "tensor([68, 68, 68, 67, 66, 66, 65, 65, 65, 65, 64, 64, 64, 64, 63, 63])\n",
      "tensor([79, 79, 78, 78, 77, 77, 77, 77, 77, 76, 76, 76, 76, 75, 75, 75])\n",
      "tensor([58, 58, 58, 58, 58, 57, 57, 57, 57, 56, 56, 56, 56, 55, 55, 55])\n",
      "tensor([46, 46, 46, 46, 45, 45, 45, 45, 45, 45, 44, 44, 44, 44, 44, 44])\n",
      "tensor([49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 46, 46])\n",
      "tensor([74, 74, 73, 72, 71, 71, 71, 71, 71, 70, 69, 69, 69, 68, 68, 68])\n",
      "tensor([51, 51, 51, 51, 50, 50, 50, 50, 50, 50, 50, 49, 49, 49, 49, 49])\n",
      "tensor([44, 44, 44, 43, 43, 43, 43, 43, 43, 42, 42, 42, 42, 42, 42, 42])\n",
      "tensor([28, 27, 27, 27, 26, 26, 26, 26, 25, 25, 25, 24, 24, 24, 24, 24])\n",
      "tensor([108, 107, 107, 106, 104, 103, 102, 102, 102, 101, 101, 101,  98,  98,\n",
      "         97,  97])\n",
      "tensor([24, 24, 23, 23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22])\n",
      "tensor([172, 170, 168, 168, 166, 165, 164, 161, 160, 160, 158, 157, 156, 155,\n",
      "        152, 150])\n",
      "tensor([12, 12, 12, 11, 11, 11,  9,  9,  9,  9,  8,  8,  8,  7,  6,  4])\n",
      "tensor([229, 225, 216, 207, 200, 196, 195, 194, 193, 186, 185, 178, 175, 174,\n",
      "        173, 173])\n",
      "tensor([247, 247, 235])\n",
      "tensor([21, 21, 21, 20, 20, 20, 20, 20, 20, 18, 18, 17, 17, 16, 15, 12])\n",
      "tensor([30, 30, 30, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 29, 28, 28])\n",
      "tensor([96, 96, 95, 95, 95, 95, 94, 94, 93, 90, 90, 89, 89, 89, 87, 86])\n",
      "tensor([131, 130, 126, 125, 123, 121, 119, 119, 118, 116, 116, 115, 113, 113,\n",
      "        109, 109])\n",
      "tensor([150, 149, 148, 146, 144, 142, 142, 141, 141, 140, 137, 137, 136, 135,\n",
      "        133, 133])\n",
      "tensor([55, 55, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 53, 53, 52, 52])\n"
     ]
    }
   ],
   "source": [
    "#Batchowanie w sieciach rekurencyjnych - wstawka\n",
    "data_iter = BucketIterator(cytaty, batch_size=16, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "for (cytat, lengths), label in data_iter:\n",
    "    print(lengths) #dlugosc cytatow w jednym batchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja do trenowania modelu\n",
    "\n",
    "def train(model, data, batch_size=1, num_epochs=1, lr=0.001, print_every=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optymalizator - Adam\n",
    "    criterion = nn.CrossEntropyLoss()  #Entropia krzyżowa jako funkcja koztu\n",
    "    it = 0  #licnzik iteraji\n",
    "    data_iter = BucketIterator(data, batch_size=batch_size, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "        avg_loss = 0 #srednia wartosc funkcji kosztu\n",
    "        for (tweet, lengths), label in data_iter:\n",
    "            target = tweet[:, 1:] #bez BOS\n",
    "            inp = tweet[:, :-1]  #bez EOS\n",
    "            optimizer.zero_grad()\n",
    "            output, hidden = model(inp)\n",
    "            loss = criterion(output.reshape(-1, vocab_size), target.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss\n",
    "            it += 1 # inkrementujemy liczbe iteracji\n",
    "            \n",
    "            if it % print_every == 0:  #co setną ierację pokaz srednią wartosc funkcji kosztu\n",
    "                print(f\"[Iter {it+1}] Loss {float(avg_loss/print_every)}\")\n",
    "                avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerator(vocab_size, 40) #budujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 101] Loss 0.22996553778648376\n",
      "[Iter 201] Loss 0.1098194569349289\n",
      "[Iter 301] Loss 0.015256743878126144\n",
      "[Iter 401] Loss 0.1886453777551651\n",
      "[Iter 501] Loss 0.10235956311225891\n",
      "[Iter 601] Loss 0.03265569359064102\n",
      "[Iter 701] Loss 0.17500537633895874\n",
      "[Iter 801] Loss 0.10474497079849243\n",
      "[Iter 901] Loss 0.043717317283153534\n",
      "[Iter 1001] Loss 0.17315396666526794\n",
      "[Iter 1101] Loss 0.11181270331144333\n",
      "[Iter 1201] Loss 0.05601189658045769\n",
      "[Iter 1301] Loss 0.17299970984458923\n",
      "[Iter 1401] Loss 0.1137675940990448\n",
      "[Iter 1501] Loss 0.06057059392333031\n",
      "[Iter 1601] Loss 0.007530189584940672\n",
      "[Iter 1701] Loss 0.13070720434188843\n",
      "[Iter 1801] Loss 0.0664728432893753\n",
      "[Iter 1901] Loss 0.026708440855145454\n",
      "[Iter 2001] Loss 0.1339685022830963\n",
      "[Iter 2101] Loss 0.08049748092889786\n",
      "[Iter 2201] Loss 0.03516561910510063\n",
      "[Iter 2301] Loss 0.1420387625694275\n",
      "[Iter 2401] Loss 0.08406105637550354\n",
      "[Iter 2501] Loss 0.038467887789011\n",
      "[Iter 2601] Loss 0.14875061810016632\n"
     ]
    }
   ],
   "source": [
    "train(model, cytaty, batch_size=32, num_epochs=200, lr=0.004, print_every=100) #trenujemy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie2: Dlaczego liczba iteracji wynosiła ok 2600 skoro zadaliśmy liczbę epok na 200?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie3: Poniżej wygenerowano dwie sekwencje (losowe cytaty) - jeden z temperaturą 0.6, drugi z 1.5. Który pochodzi z którego losowania? Dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe to be a drouds the stiveled a alless inspirational of nows when I drife we like to mig to \n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature = T))  #T=?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Withit maken van sigrent.\n"
     ]
    }
   ],
   "source": [
    "print(sample_sequence(model, temperature = T))  #T=?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Prawdopodobieństwo pozostawienia słowa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def P(w):\n",
    "    return min((np.sqrt(w/0.001)+1)*0.001/w,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZZ0lEQVR4nO3de5Bc5Xnn8e/T5/RFmpuQZiShmyWQuCgO2GQsbAIJiZMYkUpUVKgyJBsc4pSWSsh69y+o1G5SKadq1/Em6/KCrVW5sJNKymQrIQneKJDdcjBrMFijNQYEERkk64KENLprrn179o/TPdPTM5ppiZ7uOd2/T1VXn3Pet7ufg6jfeeftc06buyMiIvGXaHYBIiJSHwp0EZEWoUAXEWkRCnQRkRahQBcRaRFhsz64t7fXN27c2KyPFxGJpX379p12977Z2poW6Bs3bmRgYKBZHy8iEktmdvhybZpyERFpEQp0EZEWoUAXEWkRCnQRkRahQBcRaRHzBrqZPWVmp8zszcu0m5l92cwGzex1M7ut/mWKiMh8ahmhfwO4Z4727cCW0mMn8NUPXpaIiFypeQPd3V8Ezs7RZQfw5x55BVhmZtfWq8BqB96/xJ/80wHODE8s1EeIiMRSPebQ1wJHK9aPlbbNYGY7zWzAzAaGhoau6sPeHRrmv397kCEFuojINPUIdJtl26y/muHuu9293937+/pmvXJ1XskgKjmX1w9ziIhUqkegHwPWV6yvA47X4X1nlQqjkrOFwkJ9hIhILNUj0J8FHiqd7fJx4IK7n6jD+84qGUR/EGQ1QhcRmWbem3OZ2TeBu4FeMzsG/AGQBHD3XcAe4F5gEBgFHl6oYgHSkyP04kJ+jIhI7Mwb6O7+4DztDvxO3SqaRyoIAMjlFegiIpVid6VoMixNuWiELiIyTewCPVU6yyWrEbqIyDSxC/TyaYsaoYuITBe7QJ/8UlQjdBGRaWIX6JMXFmmELiIyTewCPaURuojIrGIb6Bqhi4hMF7tADxPlK0UV6CIilWIX6GZGKkyQLejSfxGRSrELdIjORdcIXURkungGepjQ3RZFRKrEMtCTgel+6CIiVWIZ6NEIXVMuIiKVYhnoyUCBLiJSLZaBri9FRURmimWgp8OELiwSEakSy0BPaoQuIjJDLAM9FSrQRUSqxTLQk4GmXEREqsUy0FNhggmN0EVEpolnoGuELiIyQzwDXRcWiYjMEM9ADxK69F9EpEosAz0ZmkboIiJVYhnoqSDQaYsiIlViGegaoYuIzBTLQE+XrhR11zy6iEhZLAM9GURl54sKdBGRslgGeiqMytY8uojIlFgHui4uEhGZEstAL0+5aIQuIjIlloFeHqHrfi4iIlNqCnQzu8fMDpjZoJk9Pkt7j5l9y8x+aGb7zezh+pc6JRVoykVEpNq8gW5mAfAksB3YCjxoZluruv0O8Ja73wrcDfyJmaXqXOukyS9FFegiIpNqGaFvAwbd/aC7Z4GngR1VfRzoMjMDOoGzQL6ulVYoz6Hrfi4iIlNqCfS1wNGK9WOlbZWeAG4GjgNvAJ9z9xnDZzPbaWYDZjYwNDR0lSVXjtALV/0eIiKtppZAt1m2VQ+NPwW8BqwBPgI8YWbdM17kvtvd+929v6+v7wpLnZKaPMtFI3QRkbJaAv0YsL5ifR3RSLzSw8AzHhkEDgE31afEmVJhdIzRHLqIyJRaAn0vsMXMNpW+6HwAeLaqzxHgkwBmtgq4EThYz0IrpYIA0HnoIiKVwvk6uHvezB4FngcC4Cl3329mj5TadwGfB75hZm8QTdE85u6nF6roZGmErtMWRUSmzBvoAO6+B9hTtW1XxfJx4BfqW9rlpXSlqIjIDLG8UnTy0n+N0EVEJsUy0NO626KIyAyxDHTdbVFEZKZYBrrutigiMlMsA10/cCEiMlMsAz1M6LRFEZFqsQx0MyMVJphQoIuITIploEN0LrrutigiMiW+gR4mdLdFEZEKsQ30ZGAaoYuIVIhtoEcjdM2hi4iUxTfQg4ROWxQRqRDbQE8GGqGLiFSKbaCnQ43QRUQqxTbQk0FCFxaJiFSIbaCnNEIXEZkmtoGuEbqIyHSxDfRUmGBCI3QRkUmxDnSd5SIiMiW+ga4pFxGRaWId6PpSVERkSmwDPRkauYLu5SIiUhbbQE8FgUboIiIVYhvoydD0paiISIXYBnq6NIfurmkXERGIcaCXfyha8+giIpHYBnoyKAe6pl1ERCDGgV4eoeuLURGRSGwDXSN0EZHpYhvo5RG67uciIhKJb6BrhC4iMk18A708h65AFxEBagx0M7vHzA6Y2aCZPX6ZPneb2Wtmtt/MvlPfMmcqj9D1paiISCScr4OZBcCTwM8Dx4C9Zvasu79V0WcZ8BXgHnc/YmYrF6jeSclQUy4iIpVqGaFvAwbd/aC7Z4GngR1VfX4VeMbdjwC4+6n6ljlTeYSuL0VFRCK1BPpa4GjF+rHStko3ANeY2Qtmts/MHprtjcxsp5kNmNnA0NDQ1VVckgoN0JWiIiJltQS6zbKtOkVD4CeAXwQ+BfwnM7thxovcd7t7v7v39/X1XXGxlVJBAGgOXUSkbN45dKIR+fqK9XXA8Vn6nHb3EWDEzF4EbgXeqUuVs0hOjtAV6CIiUNsIfS+wxcw2mVkKeAB4tqrP3wN3mVloZkuB24G361vqdDrLRURkunlH6O6eN7NHgeeBAHjK3feb2SOl9l3u/raZPQe8DhSBr7n7mwtZeFKBLiIyTS1TLrj7HmBP1bZdVetfBL5Yv9LmltaFRSIi08T/SlGN0EVEgBgHuu62KCIyXWwDXSN0EZHpYhvoYUKnLYqIVIptoJsZqTDBhAJdRASIcaBDdC66plxERCLxDvQwoSkXEZGSeAe6RugiIpNiHejJ0HS3RRGRklgHukboIiJTYh3oySChS/9FREpiHejpUCN0EZGyWAd6UlMuIiKTYh3oOm1RRGRK7ANdc+giIpFYB7qmXEREpsQ60DVCFxGZEu9ADzSHLiJSFvtA15SLiEgk1oGeDE2BLiJSEutATwWB7uUiIlIS70DXlaIiIpPiHeiBkS0UcdcoXUQk3oFe+qFoTbuIiMQ80JNBOdA17SIiEutAL4/QNY8uIhLzQC+P0HW1qIhIzANdI3QRkSmxDvR0qBG6iEhZrANdX4qKiEyJdaCnAk25iIiUxTrQk6FG6CIiZTUFupndY2YHzGzQzB6fo9/HzKxgZvfXr8TL68qEAFwYyzXi40REFrV5A93MAuBJYDuwFXjQzLZept8XgOfrXeTlrO7OAPD+hYlGfaSIyKJVywh9GzDo7gfdPQs8DeyYpd/vAn8DnKpjfXPq60pjBu9fGGvUR4qILFq1BPpa4GjF+rHStklmtha4D9g11xuZ2U4zGzCzgaGhoSutdYZkkKC3M837F8c/8HuJiMRdLYFus2yrvhvWl4DH3L0w1xu5+25373f3/r6+vhpLnNvq7gzvX9SUi4hIWEOfY8D6ivV1wPGqPv3A02YG0Avca2Z5d/+7ehQ5l9U9GY6cGV3ojxERWfRqGaHvBbaY2SYzSwEPAM9WdnD3Te6+0d03An8N/HYjwhzKI3RNuYiIzDtCd/e8mT1KdPZKADzl7vvN7JFS+5zz5gttdU+GC2M5xrIFlqSCZpYiItJUtUy54O57gD1V22YNcnf/jQ9eVu1WlU9dvDjOpt6ORn60iMiiEusrRaHyXHRNu4hIe4t/oPdEgX5S8+gi0uZaJtD1xaiItLvYB3pnOqQzHWrKRUTaXuwDHWBVd1qBLiJtryUCfXWPzkUXEWmNQO9eoi9FRaTttUag96Q5dWmCQrH6FjMiIu2jNQK9O0Oh6Jwe1k26RKR9tUSgr9LFRSIirRHoOhddRKTFAl1fjIpIO2uJQO/tSBMmTFMuItLWWiLQEwljZZcuLhKR9tYSgQ6wShcXiUiba5lA1y8XiUi7a51A78lwUlMuItLGWifQuzOMZAtcGs81uxQRkaZonUDv0cVFItLeWibQy1eLnlCgi0ibaplA37yyE4A33rvQ5EpERJqjZQK9tzPNTau7ePnd080uRUSkKVom0AHuuL6XvT86x3iu0OxSREQarqUC/Sc3ryCbL7Lv8LlmlyIi0nAtFejbNi0nSBgvDWraRUTaT0sFelcmya3renjp3TPNLkVEpOFaKtAB7tzcyxvHznNhTBcYiUh7ablAv2NzL0WHVw5qlC4i7aXlAv2jG5aRSSZ4WfPoItJmWi7Q02HAxzYu1zy6iLSdlgt0gJ/c3MvgqWH9JJ2ItJWWDPQ7N/cC8M//cqrJlYiINE5NgW5m95jZATMbNLPHZ2n/NTN7vfR42cxurX+ptfuxNd3cuKqLp146hLs3sxQRkYaZN9DNLACeBLYDW4EHzWxrVbdDwE+7+y3A54Hd9S70SpgZ//anr+Odk8O8cGComaWIiDRMLSP0bcCgux909yzwNLCjsoO7v+zu5evtXwHW1bfMK/dLt65hTU+GXd95t9mliIg0RC2BvhY4WrF+rLTtcj4L/ONsDWa208wGzGxgaGhhR87JIMFv3rmJVw+d5QdHdG8XEWl9tQS6zbJt1olpM/sZokB/bLZ2d9/t7v3u3t/X11d7lVfpgW0b6M6E7H7x4IJ/lohIs9US6MeA9RXr64Dj1Z3M7Bbga8AOd18UJ4F3pkMe+sRGntv/PodOjzS7HBGRBVVLoO8FtpjZJjNLAQ8Az1Z2MLMNwDPAr7v7O/Uv8+p95o6NpMMEf/it/TrjRURa2ryB7u554FHgeeBt4H+6+34ze8TMHil1+31gBfAVM3vNzAYWrOIr1NeV5vfuvZkXDgzxF68eaXY5IiILxpo1au3v7/eBgcbkvrvzma/v5fuHzvAP/+4uru/rbMjniojUm5ntc/f+2dpa8krRambGF++/hUwy4D/81WvkCsVmlyQiUndtEegAq7oz/Of7fpzXj13gj/7XW5pPF5GW0zaBDrD9x6/ls3du4s++d5g/fv6AQl1EWkrY7AIa7T/+4s2M5Qp89YV3yYQBn/u5Lc0uSUSkLtou0M2MP9rxYbL5Iv/t/7xDoVjk3//cDSQSs10/JSISH20X6ACJhPGFX7kFA7787UHeOnGRP/30R+jOJJtdmojIVWurOfRKQcL44/tv4Q9/+cd44cAQO554ibdPXGx2WSIiV61tAx2i6ZfP3LGRb+78OMMTeX75ie/yX58/wHiu0OzSRESuWFsHetnHNi7nuc/dxS/dsoYn/nmQe770Ii8cOKWzYEQkVhToJSs60/zppz/CX/7W7QD8xtf38un/8QqvHlwU9xkTEZlXW1z6f6Um8gX+au9Rnvj2IKcuTfCJ61bwm3du4mdvWkmgs2FEpInmuvRfgT6H8VyBv3jlME999xDHL4yzfvkS/s3tH+K+j65lZXem2eWJSBtSoH9A+UKRf3rrJF9/6RB7f3SOhMFdW/q476Nr+eTNK+nS6Y4i0iAK9DoaPDXM3/7gGH/7/97j+IVxUkGCOzav4Be2rubuG/tYs2xJs0sUkRamQF8AxaLzg6PneO7N93l+/0mOnB0FYPPKTn5qSx+fuH4F2zYup2epRu8iUj8K9AXm7vzrqWFefGeI77wzxKuHzpLNFzGDm1Z3c9uGZdy24Rpu+9A1bFyxFDN9sSoiV0eB3mDjuQI/PHqeVw+d5fuHzvLa0fMMT+QB6MqEfHhNDx9e283WNd3ctLqb6/s6SYU6g1RE5jdXoLflvVwWWiYZcPt1K7j9uhUAFIrO4KlhfnDkHG+8d4E337vAn33vMNl89EMbycDY1NvBlpVdbF7ZyXV9HVzf18mm3g460vonEpHaKC0aIEgYN67u4sbVXTxQ2pYrFDl0eoS3T1zkX96/xL+eHObN4xfY8+YJKv9oWtmV5kMrlrJheQcbli9l/fIlrF++lHXXLGFlV0bnxYvIJAV6kySDBDes6uKGVV3sqNg+nivwozMjHBwa4eDQMIfPjHL4zCjfHRzi5MWJae8RJoxrl2W4tmcJa3oyrO5ZwrU9GVZ1Z1jVnWZ1T4bezjTJQNM5Iu1Agb7IZJIBN62O5tarjecKvHd+jKNnR3nv/BjvnRvjvfNjnDg/zsDhc5y8eIJcYeZ3Iss7UqzsStPbmaavK01vZ4oVnWlWdKRY0ZlieUe0vLwjxdJUoC9tRWJKgR4jmWTA9X2dXN/XOWt7seicGcly8uJ46THBqUvjDF2a4NSlCU4PT3D48AhDlyYYz83+Q9mpMMHypSmWLU1yzdIU13Qk6VkSrS9bkqSn4tFd8dyVDvUjISJNpkBvIYmE0dcVjcI/vLZnzr6j2TxnhrMMDU9wdjjL2dEsZ0eynBvJcq60fH40xzsnhzk/Gi3ni5c/I8oMOlMhXZkwCvhMSGc6pCtTWs6EdKVDOtLl7dFyRzqkIxXSkQ5Kz6HO+BG5Sgr0NrU0FbJ0ecj65Utr6u/ujGYLnB/LcWE0x4Wx6HFxPMfFsdJjPM+l8TwXx3NcGs8xNDzBwdMjDI/nuTSRnzyrZz7JwFiaCulIBSxJBVGtqaD0CEvbSm3JqC2TCliSLD1SCTKTywGZcOo5nUyQDhOaVpKWpECXmpjZ5Ih67VXe3mAiX2BkosDIRJ7hisfI5KPAaDbP8ESBsWyekWy0PpotMJotMDQ8wWh2lLHS+liuUPNBYvq+QDqMQj8TBmSS0XI6TJAuPU+uVxwE0mG5z9RyKozaUkG0PRUEpeeoLRVWLFdsCxOmg4rUnQJdGiYKwYDlHam6vWe+UGQsF4X7eLbIaC7PeK7IWLbAeC56TLbnipPbJvJTy+O5IhP5qfZL43mGLk0wkS+SzU+1ZfNFsoUrP4DMxiw60yldCvnk5LNVLEfrqTAgmYi2J0t9UkG5feo1Yfm1FcvJwAgT0Xq0vdSWmL1PmJh6rzARtQXlbYloWQeixUuBLrEWBgm6gkTD7nhZLDrZQnFa2EfPU9sqt5f75gpTbeXt2XyRXMHJFqK++YIzMbl96jUXx3KT67mCT2vLF6J6coUic3zFUVdhwiYPCkH5YFDaFj1PhX95vbxcPjhUrkfPpdcE07cnqttnvC5qCxJM9im/JmGVfabeL5ilbfJhpfaK9yhvTySYfG35/RbbwU2BLnIFEgkjkwjIJINmlzJDoTgV9vmCkytGB4B8xYGgvD1f2p4tbcuX+5bbilF79Fzxmqrt+WK0XCj1KVRuL/WvrGs0G7UVilAo9Sn41GtmbC+9vtCoo9UVMqMU9hUHA2PagSZhFQeGUvuD2zbwW3ddV/d6FOgiLSIKjMV5sPmg3J2iU/pLxCcPKIWiT64Xi+UDQHRgyJcOMOVHuU/Bfdr2wizbiu6TB5eoPVouenTgnPE+XtpWpPTaqc8rekW7R3/l9XamF+S/kwJdRBY9MyMwCBKtd7CqJ53wKyLSImoKdDO7x8wOmNmgmT0+S7uZ2ZdL7a+b2W31L1VEROYyb6CbWQA8CWwHtgIPmtnWqm7bgS2lx07gq3WuU0RE5lHLCH0bMOjuB909CzwN024QSGn9zz3yCrDMzK6tc60iIjKHWgJ9LXC0Yv1YaduV9hERkQVUS6DPduZ89UmhtfTBzHaa2YCZDQwNDdVSn4iI1KiWQD8GrK9YXwccv4o+uPtud+939/6+vr4rrVVEROZQS6DvBbaY2SYzSwEPAM9W9XkWeKh0tsvHgQvufqLOtYqIyBzmvbDI3fNm9ijwPBAAT7n7fjN7pNS+C9gD3AsMAqPAw/O97759+06b2eGrrLsXOH2Vr40r7XN70D63hw+yzx+6XIO5L857JMzFzAbcvb/ZdTSS9rk9aJ/bw0Lts64UFRFpEQp0EZEWEddA393sAppA+9wetM/tYUH2OZZz6CIiMlNcR+giIlJFgS4i0iIWdaC34217a9jnXyvt6+tm9rKZ3dqMOutpvn2u6PcxMyuY2f2NrG8h1LLPZna3mb1mZvvN7DuNrrHeavh/u8fMvmVmPyzt87zXsyxmZvaUmZ0yszcv017//HL3RfkguojpXeA6IAX8ENha1ede4B+J7iXzceDVZtfdgH2+A7imtLy9Hfa5ot+3iS5iu7/ZdTfg33kZ8BawobS+stl1N2Cffw/4Qmm5DzgLpJpd+wfY558CbgPevEx73fNrMY/Q2/G2vfPus7u/7O7nSquvEN03J85q+XcG+F3gb4BTjSxugdSyz78KPOPuRwDcPe77Xcs+O9BlZgZ0EgV6vrFl1o+7v0i0D5dT9/xazIHejrftvdL9+SzRET7O5t1nM1sL3AfsamBdC6mWf+cbgGvM7AUz22dmDzWsuoVRyz4/AdxMdGO/N4DPuXuxMeU1Rd3zazH/SHTdbtsbIzXvj5n9DFGg37mgFS28Wvb5S8Bj7l6IBm+xV8s+h8BPAJ8ElgDfM7NX3P2dhS5ugdSyz58CXgN+Frge+N9m9n/d/eIC19Ysdc+vxRzodbttb4zUtD9mdgvwNWC7u59pUG0LpZZ97geeLoV5L3CvmeXd/e8aUmH91fr/9ml3HwFGzOxF4FYgroFeyz4/DPwXjyaYB83sEHAT8P3GlNhwdc+vxTzl0o637Z13n81sA/AM8OsxHq1Vmnef3X2Tu290943AXwO/HeMwh9r+3/574C4zC81sKXA78HaD66ynWvb5CNFfJJjZKuBG4GBDq2ysuufXoh2h+wLdtncxq3Gffx9YAXylNGLNe4zvVFfjPreUWvbZ3d82s+eA14Ei8DV3n/X0tzio8d/588A3zOwNoumIx9w9trfVNbNvAncDvWZ2DPgDIAkLl1+69F9EpEUs5ikXERG5Agp0EZEWoUAXEWkRCnQRkRahQBcRaREKdBGRFqFAFxFpEf8fj5b9oIrOvOEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(1e-10,1,100)\n",
    "y = np.array([P(elem) for elem in x])\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie4: \n",
    "\n",
    "\n",
    "- Wyznacz prawdopodobieństwo pozostawienia słowa występującego w korpusie z częstością 4% oraz 100% (cały korpus to tylko to słowo), czyli  P(0.04), P(1). Skomentuj otrzymane wyniki\n",
    "\n",
    "- Dla jakiej wartości częstości prawdopodobieństwo pozostawienia wynosi w przybliżenu 0.5 i 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Metody redukcji wymiarowości\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50) #embeddingi 50D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  2 -1]\n",
      " [ 3  4  0]\n",
      " [ 4  1  3]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[8,2,-1],[3,4,0],[4,1,3]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vt = np.linalg.svd(A) #rozklad macierzy A,  A = USVt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.00000000e+00,  2.00000000e+00, -1.00000000e+00],\n",
       "       [ 3.00000000e+00,  4.00000000e+00, -3.76696205e-17],\n",
       "       [ 4.00000000e+00,  1.00000000e+00,  3.00000000e+00]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U,np.diag(S)),Vt) #sprawdzenie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(random_state=42)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=2, random_state=42) #truncated SVD\n",
    "svd.fit(A) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92874673,  0.36804127,  0.04444244],\n",
       "       [ 0.07398789, -0.30149516,  0.95059269]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt = svd.components_\n",
    "Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36801455, 0.35575045])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7237649989267075"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.09318001,  3.16135545])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,-4,5],\n",
    "              [3,6,1],\n",
    "              [0,2,-13],\n",
    "              [5,6,8],\n",
    "              [-7,-2,1]])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.12824364  4.70132591]\n",
      " [-1.55726889 -4.7610173 ]\n",
      " [13.0398852  -2.97440901]\n",
      " [-8.80575535 -4.5213729 ]\n",
      " [ 1.45138268  7.55547331]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2).fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "print(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63241054 0.30814109]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[113.59251    -27.103952  ]\n",
      " [121.7994      69.201675  ]\n",
      " [134.00754     19.657959  ]\n",
      " [ 72.45755     50.437115  ]\n",
      " [ 68.14512     -0.25711372]]\n"
     ]
    }
   ],
   "source": [
    "X_tSNE = TSNE(n_components=2).fit_transform(X)\n",
    "print(X_tSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.53521359 -4.72656974]\n",
      " [-4.69629383 -1.86894848]\n",
      " [-4.38960198 12.70101156]\n",
      " [-4.06579229 -9.07048815]\n",
      " [ 7.61647451  2.96499481]]\n"
     ]
    }
   ],
   "source": [
    "X_MDS = MDS(n_components=2).fit_transform(X)\n",
    "print(X_MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD4CAYAAAAtrdtxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1QUlEQVR4nO3deXxU1fn48c9DQJTFgpVdQKi4QAgBAgYQDSiIYoEiiH5RwZaqVfq1/ZVX1SKroPgVqyIqX1r9Wi3NgLQsNVEQqiwOSAJEZEchGNYEIexLlvP740wgQEJIZrkzd5736zWvmczcufeZSTLP3HOec44YY1BKKaUqopLTASillIpcmkSUUkpVmCYRpZRSFaZJRCmlVIVpElFKKVVhlZ0O4FKuvfZac/311zsdhlJKRYzVq1cfMMbUCdXxwjqJXH/99aSnpzsdhlJKRQwR2RnK42lzllJKqQrTJBKhMjMz+cc//uF0GEqpKOd3EhGRxiLyhYhsEpENIvJMCduIiEwRke9EZJ2ItPP3uNFOk4hSKhwE4kwkH/iDMeYWIBF4WkRaXrDNPUAL3+Vx4N0AHDdi9evXj/bt29OqVSumT58OQI0aNc4+Pnv2bIYOHQrA0KFD+e///m86d+5M8+bNmT17NgDPPfccy5YtIz4+ntdffz3kr0EppSAAHevGmL3AXt/toyKyCWgEbCy2WV/gQ2Mn6lopIrVEpIHvuVHn/fff55prruHkyZN06NCB+++//5Lb7927l+XLl7N582b69OnDgAEDmDRpEpMnT+aTTz4JUdRKKXWxgPaJiMj1QFvg6wseagRkFft5l+++kvbxuIiki0h6Tk5OIMNzVNrEqeyrXY9CqcRLDRvTokEjEhMTycrKYtu2bZd8br9+/ahUqRItW7Zk//79IYpYKaXKFrAkIiI1gH8CvzPGHLnw4RKeUuL0wcaY6caYBGNMQp06ISt1Dqq0iVOJHTeC+rnZLMWw8vQJVh44wF8f+DVt27bl1KlTiJx7i06dOnXe86tWrXr2ts66rJQKJwFJIiJSBZtAZhhj/lXCJruAxsV+vg7YE4hjR4LGk1/kqrzTABwGagM/zT/DqVfGsHLlSgDq1avHpk2bKCwsZM6cOWXus2bNmhw9ejSIUSulVNkCUZ0lwHvAJmPMn0vZbD7wqK9KKxE4HE39IXVzzzXL9cJWIsQBbx49SGJiIgCTJk3ivvvuo3v37jRo0KDMfcbFxVG5cmXatGmjHetKKceIv80jInIbsAz4Fij03f0noAmAMWaaL9FMxX6GngAeM8aUORQ9ISHBuGHE+r7a9aifm33x/bXqUv+Q9nEopQJHRFYbYxJCdbxAVGctp+Q+j+LbGOBpf48VqbJGjKLOqP8mpljCPlmlKlkjRlHfwbiUUspfOmI9BDr8YRgilThWtRqFCPtq1WX9mMl0GDnc6dCUUsovYT0Bo2usWUOlwgJqeGZAv37UBz0DUUq5gp6JhILXa687dXI2jjA1bNgwNm7cWOrjH3zwAXv2RE0xn1IRRZNIKHi98LOfQb16TkcSlv7617/SsuWFM+WcU5Ekkp+f729YSqnLoEkk2IyxSaRzZ6cjCQvHjx+nd+/etGnThtjYWGbOnElSUhLp6ekUFBQwdOhQYmNjad26Na+//jqzZ88mPT2dwYMHEx8fz8mTJ1m9ejV33HEH7du35+6772bvXlstnpSUxJ/+9CfuuOMO3nzzTYdfqVLRQftEgm3HDti/X5OIz2effUbDhg1JSUkB4PDhw7z7rp2PMyMjg927d7N+/XoAcnNzqVWrFlOnTmXy5MkkJCSQl5fHb3/7W+bNm0edOnWYOXMmI0eO5P333z/7nCVLljjz4pSKQppEgq2oPyTKk0jaxKk0nvwirXKz+X2lSjy6JZNfTxxN165dz27TvHlztm/fzm9/+1t69+5Nz549L9rPli1bWL9+PT169ACgoKDgvMGZgwYNCv6LUUqdpUkk2LxeqFkTWrVyOhLHFM0ddlXeaeoDGYWFzPV+yW8f3k7/Xw05u13t2rX55ptvWLBgAW+//TazZs06e4ZRxBhDq1atWLFiRYnHql69ejBfilLqAtonEmxeLyQmQkyM05E4pvjcYXuAasAvC/J55sCPrFmz5ux2Bw4coLCwkPvvv58XX3zx7GPF5wm76aabyMnJOZtE8vLy2LBhQ0hfj1LqHE0iwXTkCHz7bdQ3ZRWfO+xboCMQD7xz4jAvvPDC2cd2795NUlIS8fHxDB06lJdffhmwC3M9+eSTxMfHU1BQwOzZs3n22Wdp06YN8fHxeIuaDJVSIef33FnBFPFzZy1aBD16wIIFUEL7frTQucOUCp1Qz52lZyLB5PWCCNx6q9OROGr3M3+8aPGYornDlFKRTZNIMHm9EBsLP/mJ05E4qv3NjRDgxxq1de4wpVxGq7OCpbAQVqyAhx5yOhLneTzQsCE//eEHiInRucOUchE9EwmWjRttx3qUd6qTmwuffgqDBkV1hZpSbqVJJFh0kKE1Zw6cOQMPPuh0JEqpINAkEixeL9SpYydejGbJydC8OXTo4HQkSqkg0CQSLEWTLsolF310t+xsWLzYnoVE8/uglIsFJImIyPsiki0i60t5PElEDotIhu8yOhDHDVs5ObBtmzZlffyxLTDQ4gKlXCtQ1VkfAFOBDy+xzTJjzH0BOl54K5rXKdqTiMdj5wyLjXU6EqVUkATkTMQYsxQ4GIh9uYLXC1WqQPv2TkfinB9+gOXL9SxEKZcLZZ9IJxH5RkQ+FRF3T2nr9UK7dnDVVU5H4pxZs+y1Ts2ulKuFKomsAZoaY9oAbwFzS9tQRB4XkXQRSc/JySlts/B15gykpWlTVnKyrci64QanI1FKBVFIkogx5ogx5pjvdipQRUSuLWXb6caYBGNMQp06dUIRXmBlZMCpU9GdRLZuhTVrdGyIUlEgJElEROqL2BpPEenoO+6PoTh2yOkgQ9uhLqJNWUpFgYBUZ4lIMpAEXCsiu4AxQBUAY8w0YADwGxHJB04CD5pwnoPeH14vNG0KDRs6HYkzjLFNWV27QqNGTkejlAqygCQRY8wlS3CMMVOxJcDuZgx89RXccYfTkThn3TrYvBmeecbpSJRSIaAj1gMpKwv27NGmrJgYuP9+pyNRSoWAJpFAivb+EGNsEunRw84bppRyPU0igeT1QrVqEBfndCTO+PpryMzUqiyloogmkUDyeu1SuJWjdK2v5GSoWhX69XM6EqVUiGgSCZTjx+0YkWhtyioosKPU77036pcDViqaaBIJlLQ0+0EarUlkyRLYt0+bspSKMppEAqWoUz0x0dk4nOLxQPXqcF90TNSslLI0iQSK1wu33ALXXON0JKF35gzMng19+9rCAqVU1NAkEgiFhXYNkWhtyvr8czh0SKd9VyoKaRIJhK1b4eDB6E0iHg/Urg09ezodSVj78ssv8RY1ewJDhw5l9uzZDkaklP80iQRCNA8yPHEC5s61I9SvuMLpaMLahUnEH8YYCgsLA7IvpfyhSSQQvF7bF3LjjU5HEnqpqXDsWNRUZWVmZnLzzTczbNgwYmNjGTx4MIsWLaJLly60aNGCVatWcfDgQfr160dcXByJiYmsW7eOzMxMpk2bxuuvv058fDzLli0DYOnSpXTu3JnmzZufd1by6quv0qFDB+Li4hgzZszZY99yyy089dRTtGvXjqysLEfeA6XOY4wJ20v79u1NRLjlFmN693Y6Cmf0729MvXrG5Oc7HUlI7Nixw8TExJh169aZgoIC065dO/PYY4+ZwsJCM3fuXNO3b18zfPhwM3bsWGOMMYsXLzZt2rQxxhgzZswY8+qrr57d15AhQ8yAAQNMQUGB2bBhg/nZz35mjDFmwYIF5te//rUpLCw0BQUFpnfv3mbJkiVmx44dRkTMihUrQv66VeQA0k0IP6f1TMRfBw/Cpk3R2ZR15AikpMADD9hJF10qbeJU9tWuR6FUIicugYa1rqF169ZUqlSJVq1aceeddyIitG7dmszMTJYvX84jjzwCQPfu3fnxxx85fPhwifvu168flSpVomXLluzfvx+AhQsXsnDhQtq2bUu7du3YvHkz27ZtA6Bp06YkRmsZuQpLUTo/RwCtXGmvozGJzJ0Lp0+7uiorbeJUYseN4Kq80wDUOfojNRHSJk6lw8jhVKpUiapVqwJQqVIl8vPzqVzCtDe+NdkuUvRcsK0CRdfPP/88TzzxxHnbZmZmUr169YC8LqUCRc9E/OX12m/hHTo4HUnoeTx2AS4XfzNuPPnFswmkiGBoPPnFUp9z++23M2PGDMB2pl977bVcffXV1KxZk6NHj5Z5zLvvvpv333+fY8eOAbB7926ys7P9eBVKBY+eifjL64X4eDtaO5ocOGDHh/zhD3YpXJeqm5tTrvsBxo4dy2OPPUZcXBzVqlXjb3/7GwA///nPGTBgAPPmzeOtt94q9fk9e/Zk06ZNdOrUCYAaNWrw97//nRgXNxmqyCVFp9DhKCEhwaSnpzsdRuny8+1kg7/6FUyZ4nQ0ofW//wtPPglr19ok6lL7atejfu7FZwH7atWl/qH9DkSk1KWJyGpjTEKojqfNWf5Yt86Ok4jG/pDkZLj5ZmjTxulIgup4j3suuu9klapkjRjlQDRKhZ+AJBEReV9EskVkfSmPi4hMEZHvRGSdiLQLxHEdF62DDHfvhqVL7dgQFzdlkZ/PzzK8nKjbgH216lKIsK9WXdaPmUyHkcOdjk6psBCoPpEPgKnAh6U8fg/Qwne5FXjXdx3ZvF5o1AgaN3Y6ktCaNcsuhev2AYYffgjbtlFt7lyq9e0LQH3fRSllBeRMxBizFDh4iU36Ah/6xsKsBGqJSINAHNtRXq89C3Hzt/GSeDzQti3cdJPTkQTP6dMwbpytuuvTx+lolApboeoTaQQUn6Nhl+++i4jI4yKSLiLpOTmlV8A4bvdu2Lkz+pqyvv8eVq1y9dgQAN57D374ASZMiL4vCUqVQ6iSSEn/hSWWhRljphtjEowxCXXq1AlyWH5YscJeR1sSmTnTXg8a5GwcwXTihE0eXbtCjx5OR6NUWAvVOJFdQPGOg+uAPSE6dnB4vXDlla4uby1RcjJ06QJNmjgdSfC8+y7s3Wub7fQsRKlLCtWZyHzgUV+VViJw2BizN0THDg6v17aXR9P05+vX24ubO9SPHoVJk+zaKLff7nQ0SoW9gJyJiEgykARcKyK7gDFAFQBjzDQgFbgX+A44ATwWiOM65uRJWLMG/t//czqS0PJ4oFIlGDjQ6UiC58037Wj8F0uf1kQpdU5Akogx5pK9rL7piZ8OxLHCwurVkJcXXf0hxtgk0r071KvndDTBcegQTJ5s14rv2NHpaJSKCDpivSKKBhn65jaKCunptjLLzVVZkyfD4cMwfrzTkSgVMTSJVITXCy1aQDhXjwWaxwNVqsAvfuF0JMGRnW2bsgYNgrg4p6NRKmJoEikvY84NMowWhYW2tPeee6B2baejCY5Jk2xf17hxTkeiVETRJFJe338POTnRlUSWL7eDK91albV7N7zzDjz6qLtH4SsVBJpEyisaJ11MToZq1dw7/cfEifZsa8wYpyNRKuJoEikvrxeuvhpatnQ6ktDIy4PZs+HnP3fnwls7dsBf/gLDhsH11zsdjVIRR5NIeXm9tiqrUpS8dYsX23ETbq3KGj8eKleGkSOdjkSpiBQln4QBcviwHbEdTU1ZHo9dvbFXL6cjCbzNm+107089Zaf0V0qVmyaR8vj6a1udFS1J5NQpmDMH+veHqlWdjibwxo6Fq66CZ591OhKlIpYmkfLwem0zVrSMZv70UzhyxJ1VWevW2bLl3/0O6tZ1OhqlIpYmkfLweqF1a9uxHg2Sk+2Ayu7dnY4k8EaNss10f/iD05EoFdE0iVyuggJYuTJ6mrKOHoVPPrGTLVYO1YoBIbJqFcyfDyNGuHfwpFIhoknkcm3YYD9YoyWJzJ9vR3C7sSrrhRfg2mvhmWecjkSpiOeyr5hBFG2DDD0euO46973eJUvg88/tZIs1azodjVIRT89ELpfXa6dAb9bM6UiC7+BBWLDAdqi7aTyMMbYvpEEDW9arlPKbnolcrqJJF6NhudR//cuOVHdbVdbChbBsGbz9ti3tVUr5zUVfM4No/3478aLbmnZKk5xsp7pv187pSALHGNsX0rSpneJEKRUQmkQux4oV9joaksjevfDFF/YsxE1nXfPm2YW1xoyBK65wOhqlyvQ///M/TJkyBYDf//73dPeV2i9evJiHH36Y5ORkWrduTWxsLM+eP2C2rYi8IiKrRWSRiHQUkS9FZLuI9AEQketFZJmIrPFdOvvuT/JtO1tENovIDJFLfxBoErkcXq/94HHTN/PSfPyx/dbupqaswkLbF3LjjfDII05Ho9Rluf3221m2bBkA6enpHDt2jLy8PJYvX06LFi149tln+c9//kNGRgZpaWnMnTu36KmVgC+NMe2Bo8AEoAfwC6Bo2c5soIcxph0wCJhS7NBtgd8BLYHmQJdLxRmQJCIivURki4h8JyLPlfB4kogcFpEM32V0II4bMl4vtG8PV17pdCTB5/HYlf3cNEvxrFl2zrNx49w35kW5StrEqeyrXY9CqUSjXn3wLv6Co0ePUrVqVTp16kR6ejrLli2jVq1aJCUlUadOHSpXrszgwYNZunRp0W4M8Jnv9rfAEmNMnu/29b77qwB/EZFvgY+xCaPIKmPMLmNMIZBR7Dkl8juJiEgM8DZwjy+Qh0SkpE+gZcaYeN8lchaxPn3aNoNEQ1NWZqZtunPT2JD8fNuEFRsLDzzgdDRKlSpt4lRix42gfm42lTA0PpxDi9yDjHvoMTp37kzXrl354osv+P7772nSpMmldmWMMcZ3uxA47buzkHPFVL8H9gNtgASgeBvv6WK3CyijACsQZyIdge+MMduNMWcAD9A3APsND2vX2kQSDUlk5kx7PWiQs3EE0kcfwdat8OKL7ipXVq7TePKLXJV3+rz7kowhOXUOt99+O127dmXatGnEx8eTmJjIkiVLOHDgAAUFBSQnJ3PHHXeU53A/Afb6EssjQExF4w7Ef1UjIKvYz7t8912ok4h8IyKfikir0nYmIo+LSLqIpOfk5AQgPD8VDTLs1MnZOEIhORkSE90zFub0aduElZAAfd3zvUa5U93ciz/vugLZppBOnTpRr149rrzySrp27UqDBg14+eWX6datG23atKFdu3b0Ld/f+DvAEBFZCdwIHK9o3HLurKeCOxAZCNxtjBnm+/kRoKMx5rfFtrkaKDTGHBORe4E3jTEtytp3QkKCSU9P9ys+vw0YAGvWwPbtzsYRbJs22X6QN95wz3Qg77wDTz8Nn30Gd9/tdDRKXdK+2vWon5t98f216lL/0P7L3o+IrDbGJAQytksJxJnILqBxsZ+vA/YU38AYc8QYc8x3OxWoIiLXBuDYwWUMfPVVdDRleTy2pNct/QYnT8KECdC1K/Ts6XQ0SpUpa8QoTsdUOe++k1WqkjVilEMRXZ5AJJE0oIWINBORK4AHgfnFNxCR+kW1xiLS0XfcHwNw7ODauRP27XN/EjHGJpGkJDsliBu8844d8zJhgrvGuyjX6jByOD927Y4BChH21arL+jGT6TByuNOhXZLf9Y7GmHwRGQ4swHbOvG+M2SAiT/oenwYMAH4jIvnASeBB4287WihEy6SLa9fazucRI5yOJDCOHoVJk+wZyO23Ox2NUpet4eFsuO02ZNky6gP1nQ7oMgSkaN7XRJV6wX3Tit2eCkwNxLFCyuuFGjVseaibeTx2/ET//k5HEhhvvgkHDtiKLKUixZ499gvdyy87HUm5aM3jpXi9cOut7h6gVlhok0jPnvDTnzodjf8OHbLTvPfpEz3LGCt3+PRTe33vvc7GUU6aREpz7Bh88437m7JWrICsLPcMMHztNTh8WM9CVORJTbVr+LRu7XQk5aJJpDSrVtlv6W5PIsnJdjoXN4yjyM62JcqDBtmpW5SKFGfO2MXS7r034gpBNImUpqhTPTHR2TiCKT/fTrh4333uWOXvlVdsae+4cU5HolT5LF9uC0IirCkLNImUzuuFVq2gVi2nIwmeL76w397dMGPv7t12salHH4WbbnI6GqXKJzXVzhR+551OR1JumkRKUlho+wrc3pTl8dgzkAj89nORiRPt7210ZE0QrRQAKSlwxx22GjTCaBIpyebNkJvr7iRy+rRdBrdfv8hfKnbHDvjrX+2KhW6Z90tFj+3b7WdOhH6Z0yRSkmgYZLhggU2UbqjKGj8eYmJg5EinI1Gq/IpKe3v3djaOCtIkUhKv146ZaFHmHJGRy+Oxr/Guu5yOxD9btsCHH8JTT0GjkiaPVirMpaTADTdE7OeNJpGSeL32LCTCSu0u2/Hjds3xAQOgSpWytw9nY8bY5rjz15hWKjKcOGELXCL0LAQ0iVzswAH77dbNTVmffGL/eCO9KmvdOruQ1jPPQN26TkejVPl9+SWcOhWx/SGgSeRiK1faazcnkeRkaNjQTpMeyUaNgp/8xD0TR6rok5IC1apF9EShmkQu5PXaubISQramS2jl5tqOvAcesJ3RkWrVKpg/3yaQ2rWdjkap8jPGjg+56y47a0SE0iRyIa8X2ra13w7caM4cO8VCpFdljRoF117rnlUYVfTZtAkyMyO6KQs0iZwvL89+w3VzU5bHA82bQ4cOTkdScUuXwsKF8Nxz7piuRUWnVN/qGZpEXOSbb+zcS25NItnZsHix7VCP1MozY+CFF+wKjE895XQ0SlVcaqqdsbdx47K3DWOaRIpz+yDD2bOhoCCyq7IWLoRly2wiifSR9ip6HT5s/44j/CwENImcz+u13wquu87pSIIjOdlOKhlh6xWcVXQW0rSpneJEqUi1aJGdRTuCx4cU0SRSXNEgQzfKyrLTTUfyWcj8+ZCebgcYXnGF09EoVXEpKbY8vVMnpyPxW0CSiIj0EpEtIvKdiDxXwuMiIlN8j68TkXaBOG5AZWXZi1uTyMyZ9jpSk0hhoa3IatECHnnE6WiUqrjCQltmf/fdrlh62+9XICIxwNtAD2AXkCYi840xG4ttdg/Qwne5FXjXdx0+Vqyw125NIh6PHftyww1OR1Ixs2bBt9/CP/7hin88FcUyMmDfPlc0ZUFgzkQ6At8ZY7YbY84AHuDCtVb7Ah8aayVQS0QaBODYgeP12o7aNm2cjiTwtm2D1asjd2xIfr5twoqNtUvfKhXJUlJsdWSvXk5HEhCB+ErXCMgq9vMuLj7LKGmbRsDeC3cmIo8DjwM0adIkAOFdJq8XOnaM/AkJS+Lx2D/aBx5wOpKK+egj2LrVDpSspN14KsKlptpxWi6Z7y0Q/5ElDTgwFdjG3mnMdGNMgjEmoU6dOn4Hd1lOnIC1a93ZlGWMrcrq2jUyq87OnLFrpickQN8LT3CVijAHDsDXX7uitLdIIJLILqD4aJnrgD0V2MY56em2ycSNSeTbb+30CpHaof7Xv8LOnTBhQuQOkFSqyGef2S92mkTOkwa0EJFmInIF8CAw/4Jt5gOP+qq0EoHDxpiLmrIcUzTIMDHR2TiCITnZTrQ4YIDTkZTfyZM2edx2G/Ts6XQ0SvkvNdU2Y7Vv73QkAeN3n4gxJl9EhgMLgBjgfWPMBhF50vf4NCAVuBf4DjgBPObvcQPK64WbbrIT+rmJMbY/5K67IFRNg4H0zjuwd++5Ph2lIll+vj0T6dPHVX17AamVNMakYhNF8fumFbttgKcDcayAM8YmkT59nI4k8L7+2s4SOnas05GU39GjMGkS9OgR0WstKHXW11/DoUOuKe0t4p50WFHbtsGPP7qzP8TjgapVoV8/pyMpvylTbCfkhAlOR6JUYKSm2qblHj2cjiSgNIm4ddLFggI7Sv3ee+30CpHk0CF49VV7dtixo9PRKBUYKSnQpQvUquV0JAGlScTrtb/Um292OpLAWrrUjoqNxKqs116zs5yOH+90JEoFxu7ddqkJlzVlgSYRm0Q6dXJVRxdgq7KqV4f77nM6kvLJzoY33rAj0904e4CKTi5ZgKokLvvkLKfcXNiwwX1NWWfOwD//aQfnRdoyv6+8Ykt7I7EYQKnSpKbaZSZatXI6koCL7iSycqW9dlsS+fxzOHgw8ubK2r3blvU++qj7mhdV9Dp92q4f0ru3K0vVozuJeL22GcttnbceD9SuHXkD9CZOtLX0o0c7HYlSgbNsGRw75sqmLNAkYtvda9RwOpLAOXEC5s6F+++PrIWbduywU5wMGwbNmjkdjVKBk5pqS+27d3c6kqCI3iSSn28H/7itKSs11X7ribSqrPHj7VnhCy84HYlSgZWSAklJttDFhaI3iaxfbz9s3ZZEkpOhXj37RxsptmyBDz+Ep56CRo2cjkapwPnuO7uMgUubsiCak4gbBxkeOWK/9TzwgB0ZGynGjrULgj130crKSkW2Tz+115pEXMjrhQYNoGlTpyMJnLlzbSVIJFVlrVtnCwGeecY1i/QodVZKCtx4Y+QuS30ZojuJdO7srpI7j8cmxUia0n70aDsty4gRTkeiVGAdPw5ffunKUerFRWcS2bvXVgO5qSnrwAE7PuTBByMnMa5aBfPm2QRSu7bT0SgVWF98YVsGXNyUBdGaRFassNduSiL//KetOIukqqxRo+waLs8843QkSgVeSoqtyOra1elIgiog64lEHK/X1m23bet0JIGTnGxHeUfKfFNLl8LChTB5MtSs6XQ0SgWWMbbcvkcP+1njYtF5JuL1QkKCe365u3fbD+VIacoyxo4HadDAlvUq5TYbNsAPP7i+KQuiMYmcOgWrV7urKWvWLPvBHClNWZ9/bqeCeOEFW9qrlNsUzdp7zz3OxhECfjVnicg1wEzgeiATeMAYc6iE7TKBo0ABkG+MSfDnuH5Zs8bOcuumJOLx2Ka5m25yOpKyGQMjR9oqsl/9yulolAqO1FTbtHzddU5HEnT+nok8Byw2xrQAFvt+Lk03Y0y8owkEzg0y7NTJ0TAC5vvvbZVTpIwNmT8f0tNtaa9bmhOVKi43F5Yvj4qmLPA/ifQF/ua7/Tegn5/7Cz6vF372Mzs1iBvMnGmvBw1yNo7LUVhoK7JatLDTvSvlRp9/bpendvn4kCL+JpF6xpi9AL7r0oYcG2ChiKwWkcf9PGbFGXNukKFbJCfbdZubNHE6krLNmgXffgvjxkHl6CwMVFEgJcWOe7r1VqcjCYky/5NFZBFQv4SHRpbjOF2MMXtEpC7wuYhsNsYsLeV4jwOPAzQJ9Afjjh2wf797ksj69fby1ltOR1K2/HwYMwZiYyPjrEmpiigstPNl3X131HxRKvNVGmPuKu0xEdkvIg2MMXtFpAGQXco+9vius0VkDtARKDGJGGOmA9MBEhISTNkvoRzcNumix2OnTx840OlIyvbRR3Y20zlz3LeevVJF1qyB7OyoacoC/5uz5gNDfLeHAPMu3EBEqotIzaLbQE9gvZ/HrRiv1w5sc8M6x8bYJNK9e/j375w5Y5uwEhLsuu9KuVVKih2rdffdTkcSMv4mkUlADxHZBvTw/YyINBQRX6E09YDlIvINsApIMcZ85udxK8brtZMTRtI06aVJT7eVWZEwNuS992DnTpgwITIGQypVUampti+kTh2nIwkZvxrtjDE/AneWcP8e4F7f7e2A83NxHDliO3VHjXI6ksDweKBKFejf3+lILu3kSZs8brst8tZ8V6o8srMhLc2edUeR6Oj5ATuWorDQHf0hhYW2tLdXr/Cf/fbdd2HPHltFpmchys0++8w2M0fJ+JAi0dPD6fXaDzE3lN0tX27nywr3AYZHj8LLL9tJ6G6/3elolAqu1FSoX99dE7tehuhKIrGxdgGkSOfx2Dmnfv5zpyO5tClT7DonEyY4HYlSwZWfDwsW2Lmyoqz6MDpebWGhXUPEDU1ZeXnw8cfQpw/UqOF0NKU7dAhefdXG2bGj09EoFVwrVtjpTqKsKQuiJYls3Gg71t2QRP7zH/vtPtyrsl57DQ4fhvHjnY5EqeBLTbWDC3v0cDqSkIuOJOKmQYbJybZJLpynmM7JgTfesCPTI2WRLKX8kZJiKxDd0FxeTtGTROrUsRMvRrJTp+yI71/8IrxnwJ00yZb2jh3rdCRKBV9Wlh0+EEWj1IuLniTSuXPkl5h++qltlgvnqqzdu+Gdd+CRR+xyvUq5XdECVFHYHwLRkERycmDbNnc0ZXk89oyqe3enIyndSy+dm2xRqWiQmmoXWbvlFqcjcYT7k8iKFfY60pPIsWPw73/byRbDdXbQzEz4y19g2DBo1szpaJQKvtOnYdEi25QV6S0dFeT+JOL12ulB2rd3OhL/zJ9v+xnCuSpr/HhbI//CC05HolRoLFkCJ05EbVMWREsSadfODs6LZMnJdr3mLl2cjqRkW7bA3/4GTz0FjRo5HY1SoZGaCldeCd26OR2JY9ydRM6csROiRXpT1sGDdjTsoEHhOxp27FibqJ97zulIlAqd1FSbQKpVczoSx4TpJ1KAZGTYsthITyL/+pcdqR6uVVnr1tlO/2eegbqlrZCslMts22YvUdyUBW5PIm4ZZOjxwA032Ga5cDR6tB1kNWKE05EoFTpRXtpbxP1JpGlTaNjQ6Ugqbt8++OILexYSjtUfaWkwb55NIOE+Lb1SgZSSYsdCNW/udCSOcm8SMQa++iryz0I+/thOIBmuVVkvvAA//altylIqWhw7ZiuzonSUenFhOuAgALKy7GJIkZ5EkpMhLg5atnQ6kostXQoLF9rZemvWdDoapULnP/+xhTtR3pQFbj4TcUN/SGamHSwZjmchxtizkAYNbFmvUtEkJcV+cbrtNqcjcZxfSUREBorIBhEpFJGES2zXS0S2iMh3IhKaGlCv15bdxcX5vaukpCTS09MDEFQ5zZxpr8MsiUyZMoVbmjZl8LJlMHLkReWNGRkZpBZ1OgJjx45l8uTJoQ5TqeAwxnaq9+gBV1zhdDSO8/dMZD3QH1ha2gYiEgO8DdwDtAQeEpHgt814vXYp3HCdIuRyeDz2NYTZFCLvvPMOqbVrM6NpUzvFyQUuTCL+KigoCNi+lPLbt9/Crl3alOXjVxIxxmwyxmwpY7OOwHfGmO3GmDOAB+jrz3HLdPw4ZGSQ2bIlsbGxZ++ePHkyY8eOJSkpiWeffZaOHTty4403smzZMsB+WI0YMYLWrVsTFxfHW2+9ddGuFy5cSKdOnWjXrh0DBw7k2LFjwXkNmzfbcS5hNjbkySefZPv339Nn3TpeSUigc7dutG3bls6dO7NlyxbOnDnD6NGjmTlzJvHx8cz0nU1t3LiRpKQkmjdvzpQpU87u7+9//zsdO3YkPj6eJ5544mzCqFGjBqNHj+bWW29lRdH8Z0qFg6IvSOG8pk8IhaJPpBGQVeznXb77SiQij4tIuoik5+TkVOyIaWlQUHDJ+bLy8/NZtWoVb7zxBuPGjQNg+vTp7Nixg7Vr17Ju3ToGDx583nMOHDjAhAkTWLRoEWvWrCEhIYE///nPFYuxLB6PLekdODA4+6+gae+8Q0MRvmjenN9Mn87SpUtZu3Yt48eP509/+hNXXHEF48ePZ9CgQWRkZDBo0CAANm/ezIIFC1i1ahXjxo0jLy+PTZs2MXPmTL766isyMjKIiYlhxowZABw/fpzY2Fi+/vprbtN2ZxVOUlOhbdvIHjoQQGW29YjIIqB+CQ+NNMbMu4xjlDS4wZS2sTFmOjAdICEhodTtSpM2cSo3T3iOmkDOMyM4eVXJizf1798fgPbt25OZmQnAokWLePLJJ6nsawK75pprznvOypUr2bhxI11881edOXOGTp06lTfEshljq7KSksLmDzVt4lQaT36RernZAOyI7UD948cZ8qtfsW3bNkSEvLy8Up/fu3dvqlatStWqValbty779+9n8eLFrF69mg4dOgBw8uRJ6vpGvMfExHD//fcH/4UpVR6HDtmmcp3e56wyk4gx5i4/j7ELaFzs5+uAPX7us0RpE6cSO24EV+WdBqDB0YNccVRImziVDiOHc+rUqbPbVvWtDBgTE0N+fj4AxhjkEgP6jDH06NGD5OTkYIR/TkYGbN0Kf/hDcI9zmS58XwHqp8zhN1k76Dl0MHPmzCEzM5OkpKRS91G12EqMRe+5MYYhQ4bw8ssvX7T9lVdeSUxMTEBfh1J+W7jQtnLo+JCzQtGclQa0EJFmInIF8CAwPxgHajz5xfM+6OoBORiq/884Tp8+zSeffHLJ5/fs2ZNp06adTSoHDx487/HExES++uorvvvuOwBOnDjB1q1bA/siwJ6FVK4MYfJN/ML3FeCqgjMUrM+gkW/G3g8++ODsYzVr1uTo0aNl7vfOO+9k9uzZZGfbs5uDBw+yc+fOwAWuVKClpsI110DHjk5HEjb8LfH9hYjsAjoBKSKywHd/QxFJBTDG5APDgQXAJmCWMWaDf2GXrG7u+X0oVYDRQJ8jB7jvvvu4uYzlWocNG0aTJk2Ii4ujTZs2/OMf/zjv8Tp16vDBBx/w0EMPERcXR2JiIps3bw7siygstKW9PXvakeBh4ML3tcgLeWd4/vnn6dKly3kVVN26dWPjxo3ndayXpGXLlkyYMIGePXsSFxdHjx492Lt3b8DjVyogCgvtEtW9eoGeJZ8lxpS72yFkEhISTHnGZ+yrXY/6vjb78+6vVZf6h/YHMrTg+eorO4Dpo4/g4YedjgZwyfuqlL9WrbIl9zNmwH/9l9PRlEpEVhtjSh23F2iuGrGeNWIUJ6uc35F+skpVskaMciiiCvB47CI3fYNbBV0ernhflfJXSopdz+fuu52OJKy4Kol0GDmc9WMms69WXQoR9tWqy/oxk+kwcrjToV2e/HyYNQvuuy+s5qKK+PdVqUBITYXExLBpZg4XrmrOiniLFtmpFGbPDptOdaUUsH8/1K8PEybYqX7CmDZnRbPkZHsGotMpKBVePv3UXuv/5kU0iYSL06ftMrj9+tm1ypVS4SM11c5YHR/vdCRhR5NIuFiwAHJzw26uLKWiXl6e/f+8997wXF3UYZpEwoXHYzvs7vJ3ggClVEB5vXDkiDZllUKTSDg4ftyuUz5gAFSp4nQ0SqniUlPt/6V+wSuRJpFw8MkncOJE2C0+pZTCjg/p2hWuvtrpSMKSJpFwkJxsZ+vt2tXpSJRSxe3cCRs26ISLl6BJxGm5ubZ88IEHdD4epcKNlvaWSZOI0+bMgTNntCpLqXCUkmKXp77pJqcjCVuaRJzm8UDz5uBbmEkpFSZOnYLFi21Tlpb2lkqTiJOys+0f6YMP6h+pUuHmyy/h5EltyiqDJhEnzZ5tV0nTqiylwk9qqp094hIrdipNIs5KToZWraB1a6cjUUoVZ4ztD+neXachKoMmEadkZcHy5XoWolQ42roVtm/XpqzLoEnEKUXLxmoSUSr8pKbaa00iZdIk4hSPBxIS4IYbnI5EKXWhlBQyb7iBm3v1YtiwYcTGxjJ48GAWLVpEly5daNGiBatWrWLVqlV07tyZtm3b0rlzZ7Zs2QLABx98QP/+/enVqxctWrTgj3/8o8MvKIiMMRW+AAOBDUAhkHCJ7TKBb4EMIP1y99++fXvjSlu3GgPGvPaa05EopS505IgxVaqYHb/+tYmJiTHr1q0zBQUFpl27duaxxx4zhYWFZu7cuaZv377m8OHDJi8vzxhjzOeff2769+9vjDHm//7v/0yzZs1Mbm6uOXnypGnSpIn54YcfQhJ+eT5jA3Gp7GcOWg/0B/73MrbtZow54Ofx3MHjsdcPPOBsHEqp86RNnMoNL79A7bw8Ds2YScNa19DaV/jSqlUr7rzzTkSE1q1bk5mZyeHDhxkyZAjbtm1DRMjLyzu7rzvvvJOf/OQnALRs2ZKdO3fSuHFjR15XMPnVnGWM2WSM2RKoYKKCMbYqq2tXuO46p6NRSvmkTZxK7LgR1D5+GIDaJ45Q88cDpE2cCkClSpWoWrXq2dv5+fmMGjWKbt26sX79ev79739z6tSps/sr2hYgJiaG/Pz8EL6a0AlVn4gBForIahF5/FIbisjjIpIuIuk5OTkhCi90Mj/7jNhNmyo8zclLL710bl+ZmcTGxgYqNKWiWuPJL3JV3unz7hMMjSe/WOpzDh8+TKNGjQDbDxKNykwiIrJIRNaXcOlbjuN0Mca0A+4BnhaR20vb0Bgz3RiTYIxJqFOnTjkOESHmz7fXAwaUuklBQUGpjxVPIv5y6zcjpSqibm7JX1pLux/gj3/8I88//zxdunS55P+tm4nth/FzJyJfAiOMMemXse1Y4JgxZnJZ2yYkJJj09DJ3GTmMIbNxY3rl5nLr/fezdu1abrzxRj788ENatmzJL3/5SxYuXMjw4cMxxvDSSy9hjKF379688sorPPfcc7z66qu0bt2aVq1aMXHiRO655x5uu+02vF4vjRo1Yt68eVx11VV8//33PP300+Tk5FCtWjX+8pe/cPPNNzN06FCuueYa1q5dS7t27XjttdecfleUCgv7atejfm72xffXqkv9Q/sdiKhiRGS1MSYhZAcMRO888CWlVGcB1YGaxW57gV6Xs1/XVWetXGl22KY9s3z5cmOMMY899ph59dVXTdOmTc0rr7xijDFm9+7dpnHjxiY7O9vk5eWZbt26mTlz5hhjjKlevfrZ3e3YscPExMSYtWvXGmOMGThwoPnoo4+MMcZ0797dbN261XfYlaZbt27GGGOGDBlievfubfLz80PxipWKGKsmvGVOVKlqKyd9lxNVqppVE95yOrRyIcTVWX71iYjIL0RkF9AJSBGRBb77G4qIb7QO9YDlIvINsApIMcZ85s9xI03axKnsq10Pk5iIAepdXYsuXboA8PDDD7N8+XIABg0aZLdPSyMpKYk6depQuXJlBg8ezNKlS0vcd7NmzYiPjwegffv2ZGZmcuzYMbxeLwMHDiQ+Pp4nnniCvXv3nn3OwIEDidG1S5Q6T4eRw1k/ZjL7atWlEGFfrbqsHzOZDiOHOx1aWPOrxNcYMweYU8L9e4B7fbe3A238OU4kK6r4KOqwE+CKI7mkTZx69o9TfDP4Vq9eHaDoDO6yXFgBcvLkSQoLC6lVqxYZGRklPqfoOEqp83UYORx8/5f1fRd1aTpiPchKqvjIAvZPGg1AcnIyt91223mP33rrrSxZsoQDBw5QUFBAcnIyd9xxBwBVqlQ5rxa9JFdffTXNmjXj448/BmxS+uabbwL0ipRS6hxNIkFWUmXHLcC/jx0iLi6OgwcP8pvf/Oa8xxs0aMDLL79Mt27daNOmDe3ataNvX1sM9/jjjxMXF8fgwYMvedwZM2bw3nvv0aZNG1q1asW8efMC9pqUUqpIQKqzgsUN1VluqfhQSkWGUFdn6ZlIkGWNGMXJKlXPu+9klapkjRjlUERKKRU4mkSCTCs+lFJups1ZSinlItqcpZRSKmJoElFKKVVhmkSUUkpVmCYRpZRSFaZJRCmlVIWFdXWWiOQAO4vddS2gS+xa+l6co+/F+fT9OCca34umxpiQLcYU1knkQiKSHsrStXCm78U5+l6cT9+Pc/S9CD5tzlJKKVVhmkSUUkpVWKQlkelOBxBG9L04R9+L8+n7cY6+F0EWUX0iSimlwkuknYkopZQKI5pElFJKVVjEJREReVVENovIOhGZIyK1nI7JKSIyUEQ2iEihiERlGaOI9BKRLSLynYg853Q8ThKR90UkW0TWOx2L00SksYh8ISKbfP8jzzgdk1tFXBIBPgdijTFxwFbgeYfjcdJ6oD+w1OlAnCAiMcDbwD1AS+AhEWnpbFSO+gDo5XQQYSIf+IMx5hYgEXg6yv82gibikogxZqExJt/340rgOifjcZIxZpMxZovTcTioI/CdMWa7MeYM4AH6OhyTY4wxS4GDTscRDowxe40xa3y3jwKbgEbORuVOEZdELvBL4FOng1COaQRkFft5F/pBoS4gItcDbYGvHQ7FlSo7HUBJRGQRUL+Eh0YaY+b5thmJPWWdEcrYQu1y3osoJiXcpzXr6iwRqQH8E/idMeaI0/G4UVgmEWPMXZd6XESGAPcBdxqXD3Qp672IcruAxsV+vg7Y41AsKsyISBVsAplhjPmX0/G4VcQ1Z4lIL+BZoI8x5oTT8ShHpQEtRKSZiFwBPAjMdzgmFQZERID3gE3GmD87HY+bRVwSAaYCNYHPRSRDRKY5HZBTROQXIrIL6ASkiMgCp2MKJV+BxXBgAbbjdJYxZoOzUTlHRJKBFcBNIrJLRH7ldEwO6gI8AnT3fU5kiMi9TgflRjrtiVJKqQqLxDMRpZRSYUKTiFJKqQrTJKKUUqrCNIkopZSqME0iSimlKkyTiFJKqQrTJKKUUqrC/j9k16qKRSfrOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = []\n",
    "words = ['woman', 'man', 'sister','brother', 'uncle', 'aunt', 'mother', 'father'] #wybieram grupe slow\n",
    "for word in words:\n",
    "    X.append(glove[word].tolist()) #patrze jakie mają embeddingi\n",
    "    \n",
    "X = np.array(X) #tworze z nich macierz\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)  #redukuje liczbe zmiennych z 50 do 2 dla kazdego slowa\n",
    "\n",
    "\n",
    "#Do rysowania: \n",
    "\n",
    "x = X_pca[:,0] #pierwsza zmienna\n",
    "y = X_pca[:,1] #druga zmienna\n",
    "\n",
    "\n",
    "plt.scatter(x,y)\n",
    "\n",
    "for i, txt in enumerate(words):\n",
    "    plt.annotate(txt, (x[i], y[i]))\n",
    "    \n",
    "for i in range(0, len(x), 2):\n",
    "    plt.plot(x[i:i+2], y[i:i+2], 'ro-')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie5:\n",
    "\n",
    "Zaznacz na płaszczyźnie (i połącz linią) następujące nazwy państw/stolic: 'france', 'paris', 'poland', 'warsaw', 'germany', 'berlin', 'netherlands', 'amsterdam'. Do redukcji ilości zmiennych wykorzystaj PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Zadanie6:\n",
    "\n",
    "Zaznacz na płaszczyźnie (nie łącz) następujące słowa: 'dog', 'cat', 'cow', 'horse', 'sheep', 'sunflower', 'carrot', 'salad', 'potato','cucumber'. Do redukcji ilości zmiennych wykorzystaj MDS. Czy obserwujesz jakąś zależność?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
